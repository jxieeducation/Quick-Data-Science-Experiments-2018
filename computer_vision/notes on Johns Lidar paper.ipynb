{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "src: email"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* lidar\n",
    "* image centering problem\n",
    "* CX and X - center X\n",
    "* fringe - borders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### preprocessing\n",
    "* need to normalize\n",
    "    * physical dimensions\n",
    "    * dynamic range\n",
    "* variable numbers of pixels per image\n",
    "* subregions\n",
    "    * full image\n",
    "    * top half\n",
    "    * middle\n",
    "    * top half middle\n",
    "    * bottom half middle\n",
    "    * lower half\n",
    "* normalization methods\n",
    "    * normalize raw floating pts\n",
    "    * dynamic range stretching\n",
    "    * threshold intensities\n",
    "    * threshold top differently from bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### arch\n",
    "* input - 400x400x1\n",
    "* 200x200x10\n",
    "* 100x100x10\n",
    "* 50x50x10\n",
    "* 128 -> 64 -> 32 -> 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### results\n",
    "* normalization didn't yield benefits \n",
    "* exp: \n",
    "    * best result came by doing 600x300 only\n",
    "    * 3 layers on top\n",
    "* vis\n",
    "    * random model vs trained with irrelavant parts of data vs trained properly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### confusions:\n",
    "* 3D - MSE / MAD can't be compared directly\n",
    "* net shorthands for experiment 1-10, e.g. conv(2,1,10), conv(2,1,10), conv(2,1,10), fc128, fc64, fc32, fc4 \n",
    "* write a explicit loss function for how MSE is calculated, inputs, function...etc.\n",
    "* how is lower dim inputs archieved (600x600 vs 600x300)? scaling the whole image? or just croping parts of the image?\n",
    "* other metrics might help: R2 (sklearn has some great implementations), "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### suggestions:\n",
    "* batch normalization for regularization\n",
    "* since speed is important, profile the net layer by layer - https://github.com/tensorflow/tensorflow/blob/master/tensorflow/core/profiler/README.md\n",
    "    * can get time (ms) for each layer\n",
    "* visualize filters more directly - http://cs231n.github.io/understanding-cnn/\n",
    "    * layer activation\n",
    "    * visualize weights directly\n",
    "    * retrieving images with highest MSE \n",
    "    * occlusion heatmap\n",
    "* reference research literature on image localization\n",
    "    * slides 12 - http://cs231n.stanford.edu/slides/2016/winter1516_lecture8.pdf \n",
    "        * localization as regression\n",
    "        * sliding window\n",
    "        * detection as classification\n",
    "        * region proposal\n",
    "* region proposal: https://www.quora.com/How-does-the-region-proposal-network-RPN-in-Faster-R-CNN-work\n",
    "    * change problem formulation to be like appendix C - https://arxiv.org/pdf/1311.2524.pdf\n",
    "    * G<x, y, w, h> instead of <x1, y1, x2, y2>\n",
    "    * transformed truth\n",
    "    * regression with L2 reg\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
